{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Create the new directory for the small train, test and validation dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:26:23.583687Z","iopub.status.busy":"2024-11-27T03:26:23.582947Z","iopub.status.idle":"2024-11-27T03:26:38.654448Z","shell.execute_reply":"2024-11-27T03:26:38.653577Z","shell.execute_reply.started":"2024-11-27T03:26:23.583648Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","import random\n","\n","real_images_dir = '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/train/real'\n","fake_images_dir = '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/train/fake'\n","\n","new_train_dir = '/kaggle/working/train_n'\n","new_real_dir = os.path.join(new_train_dir, 'real')\n","new_fake_dir = os.path.join(new_train_dir, 'fake')\n","\n","os.makedirs(new_real_dir, exist_ok=True)\n","os.makedirs(new_fake_dir, exist_ok=True)\n","\n","real_images = os.listdir(real_images_dir)\n","fake_images = os.listdir(fake_images_dir)\n","\n","selected_real_images = random.sample(real_images, 1000)\n","selected_fake_images = random.sample(fake_images, 1000)\n","\n","for img in selected_real_images:\n","    shutil.copy(os.path.join(real_images_dir, img), os.path.join(new_real_dir, img))\n","\n","for img in selected_fake_images:\n","    shutil.copy(os.path.join(fake_images_dir, img), os.path.join(new_fake_dir, img))\n","\n","print(\"Images copied successfully to 'train_new' directory!\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:26:42.911660Z","iopub.status.busy":"2024-11-27T03:26:42.910849Z","iopub.status.idle":"2024-11-27T03:26:47.611999Z","shell.execute_reply":"2024-11-27T03:26:47.611178Z","shell.execute_reply.started":"2024-11-27T03:26:42.911626Z"},"trusted":true},"outputs":[],"source":["new_train_dir = '/kaggle/working/valid_n'\n","new_real_dir = os.path.join(new_train_dir, 'real')\n","new_fake_dir = os.path.join(new_train_dir, 'fake')\n","\n","os.makedirs(new_real_dir, exist_ok=True)\n","os.makedirs(new_fake_dir, exist_ok=True)\n","\n","real_images = os.listdir(real_images_dir)\n","fake_images = os.listdir(fake_images_dir)\n","\n","selected_real_images = random.sample(real_images, 200)\n","selected_fake_images = random.sample(fake_images, 200)\n","\n","for img in selected_real_images:\n","    shutil.copy(os.path.join(real_images_dir, img), os.path.join(new_real_dir, img))\n","\n","for img in selected_fake_images:\n","    shutil.copy(os.path.join(fake_images_dir, img), os.path.join(new_fake_dir, img))\n","\n","print(\"Images copied successfully to 'valid_new' directory!\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["new_train_dir = '/kaggle/working/test_n'\n","new_real_dir = os.path.join(new_train_dir, 'real')\n","new_fake_dir = os.path.join(new_train_dir, 'fake')\n","\n","# Create the new directories\n","os.makedirs(new_real_dir, exist_ok=True)\n","os.makedirs(new_fake_dir, exist_ok=True)\n","\n","real_images = os.listdir(real_images_dir)\n","fake_images = os.listdir(fake_images_dir)\n","\n","selected_real_images = random.sample(real_images, 200)\n","selected_fake_images = random.sample(fake_images, 200)\n","\n","for img in selected_real_images:\n","    shutil.copy(os.path.join(real_images_dir, img), os.path.join(new_real_dir, img))\n","\n","for img in selected_fake_images:\n","    shutil.copy(os.path.join(fake_images_dir, img), os.path.join(new_fake_dir, img))\n","\n","print(\"Images copied successfully to 'test_n' directory!\")"]},{"cell_type":"markdown","metadata":{},"source":["### Data Augmentation "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n","\n","prep_train = ImageDataGenerator(preprocessing_function = preprocess_input,\n","                                   rotation_range=30, \n","                                   width_shift_range=0.2, \n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True,)\n","prep_val = ImageDataGenerator(preprocessing_function = preprocess_input,\n","                                   rotation_range=30,\n","                                   width_shift_range=0.2, \n","                                   height_shift_range=0.2, \n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True,)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:27:59.808223Z","iopub.status.busy":"2024-11-27T03:27:59.807830Z","iopub.status.idle":"2024-11-27T03:27:59.846522Z","shell.execute_reply":"2024-11-27T03:27:59.845671Z","shell.execute_reply.started":"2024-11-27T03:27:59.808187Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# train_dataset = tf.keras.utils.image_dataset_from_directory(\n","#     '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/train',\n","#     labels='inferred',\n","#     label_mode='binary',\n","#     class_names=[\"fake\",\"real\"],\n","#     color_mode='rgb',\n","#     batch_size=32,\n","#     image_size=(224, 224),\n","#     shuffle=True\n","# )\n","train_dataset = prep_train.flow_from_directory(\n","  '/kaggle/working/train_n',\n","  target_size=(224,224),\n","  batch_size=32,\n","  class_mode='binary', \n","  shuffle=True\n",")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:33:35.412201Z","iopub.status.busy":"2024-11-27T03:33:35.411637Z","iopub.status.idle":"2024-11-27T03:33:35.427981Z","shell.execute_reply":"2024-11-27T03:33:35.427082Z","shell.execute_reply.started":"2024-11-27T03:33:35.412166Z"},"trusted":true},"outputs":[],"source":["# val_dataset = tf.keras.utils.image_dataset_from_directory(\n","#     '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/valid',\n","#     labels='inferred',\n","#     label_mode='binary',\n","#     class_names=[\"fake\", \"real\"],\n","#     color_mode='rgb',\n","#     batch_size=32,\n","#     image_size=(224, 224),\n","#     shuffle=False,\n","#     seed=99,\n","# )\n","\n","val_dataset = prep_val.flow_from_directory(\n","    '/kaggle/working/valid_n',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary', \n","    shuffle=True,      \n",")"]},{"cell_type":"markdown","metadata":{},"source":["\n","### Sample Images plot"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:28:03.706723Z","iopub.status.busy":"2024-11-27T03:28:03.705986Z","iopub.status.idle":"2024-11-27T03:28:05.068673Z","shell.execute_reply":"2024-11-27T03:28:05.067899Z","shell.execute_reply.started":"2024-11-27T03:28:03.706687Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","images, labels = next(iter(train_dataset))\n","\n","plt.figure(figsize=(5, 5))\n","\n","for i in range(15):\n","    ax = plt.subplot(3, 5, i + 1)\n","    plt.imshow(images[i].astype(\"uint8\"))  # Convert to uint8 for display\n","    plt.title(\"Fake\" if labels[i] == 0 else \"Real\") \n","    plt.axis(\"off\")  \n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:32:41.455997Z","iopub.status.busy":"2024-11-27T03:32:41.454580Z","iopub.status.idle":"2024-11-27T03:32:41.461550Z","shell.execute_reply":"2024-11-27T03:32:41.460527Z","shell.execute_reply.started":"2024-11-27T03:32:41.455930Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training samples: 2000\n"]}],"source":["print(f\"Number of training samples: {train_dataset.samples}\")"]},{"cell_type":"markdown","metadata":{},"source":["### VGG19 Fine-Tuned 20 layers "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:33:57.079762Z","iopub.status.busy":"2024-11-27T03:33:57.079401Z","iopub.status.idle":"2024-11-27T03:33:58.783838Z","shell.execute_reply":"2024-11-27T03:33:58.783127Z","shell.execute_reply.started":"2024-11-27T03:33:57.079731Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Load the VGG19 model without the top classification layers\n","base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the base model layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add custom layers on top of the VGG19 base\n","x = base_model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(1024, activation='relu')(x)  # 1st dense layer\n","x = layers.Dropout(0.5)(x)  # 1st Dropout for regularization\n","x = layers.Dense(512, activation='relu')(x)  # 2nd  dense layer\n","x = layers.Dropout(0.3)(x)  # 3rd dropout layer\n","x = layers.Dense(256, activation='relu')(x)  # 3rd  dense layer\n","x = layers.Dropout(0.2)(x)  # 3rd dropout layer\n","predictions = layers.Dense(1, activation='sigmoid')(x)  # Output layer for classification\n","\n","ft_model = Model(inputs=base_model.input, outputs=predictions)\n","for layer in base_model.layers[-20:]:\n","    layer.trainable = True\n","\n","ft_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Summary of the model (optional)\n","# model.summary()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:34:41.315255Z","iopub.status.busy":"2024-11-27T03:34:41.314571Z","iopub.status.idle":"2024-11-27T03:38:18.232027Z","shell.execute_reply":"2024-11-27T03:38:18.230977Z","shell.execute_reply.started":"2024-11-27T03:34:41.315217Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',  # or another metric you want to monitor\n","    patience=5,  # number of epochs to wait before stopping if no improvement\n","    restore_best_weights=True  # restore the best weights from the training\n",")\n","\n","history = ft_model.fit(\n","    train_dataset,\n","    epochs=25,  # set a large number of epochs as the upper bound\n","    validation_data=val_dataset,\n","    callbacks=[early_stopping]\n",")\n","\n","pd.DataFrame(history.history).plot(\n","figsize=(8, 5), xlim=[0, 20], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n","style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n","plt.show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:40:08.332618Z","iopub.status.busy":"2024-11-27T03:40:08.332264Z","iopub.status.idle":"2024-11-27T03:40:08.348210Z","shell.execute_reply":"2024-11-27T03:40:08.347593Z","shell.execute_reply.started":"2024-11-27T03:40:08.332579Z"},"trusted":true},"outputs":[],"source":["prep_test = ImageDataGenerator(\n","    preprocessing_function=preprocess_input, \n",")\n","test_dataset = prep_val.flow_from_directory(\n","    '/kaggle/working/test_n',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',  \n","    shuffle=False  \n",")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:40:13.167877Z","iopub.status.busy":"2024-11-27T03:40:13.167531Z","iopub.status.idle":"2024-11-27T03:40:17.804379Z","shell.execute_reply":"2024-11-27T03:40:17.803495Z","shell.execute_reply.started":"2024-11-27T03:40:13.167847Z"},"trusted":true},"outputs":[],"source":["test_loss, test_accuracy = ft_model.evaluate(test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["### VGG19 Base Model"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:47:42.143458Z","iopub.status.busy":"2024-11-27T03:47:42.143116Z","iopub.status.idle":"2024-11-27T03:47:42.451743Z","shell.execute_reply":"2024-11-27T03:47:42.450737Z","shell.execute_reply.started":"2024-11-27T03:47:42.143427Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Load the VGG19 model without the top classification layers\n","base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(1, activation='sigmoid')(x)  \n","\n","vggbase_model = Model(inputs=base_model.input, outputs=predictions)\n","\n","vggbase_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Summary of the model (optional)\n","# model.summary()\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T03:49:06.181168Z","iopub.status.busy":"2024-11-27T03:49:06.180802Z","iopub.status.idle":"2024-11-27T03:52:45.649889Z","shell.execute_reply":"2024-11-27T03:52:45.648685Z","shell.execute_reply.started":"2024-11-27T03:49:06.181138Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',  \n","    patience=5,  \n","    restore_best_weights=True  \n",")\n","\n","history = vggbase_model.fit(\n","    train_dataset,\n","    epochs=25,  \n","    validation_data=val_dataset,\n","    callbacks=[early_stopping]\n",")\n","\n","pd.DataFrame(vggbase_model.history).plot(\n","figsize=(8, 5), xlim=[0, 20], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n","style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","test_loss, test_accuracy = vggbase_model.evaluate(test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["### Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","\n","y_true = test_dataset.classes  # True labels\n","y_pred = vggbase_model.predict(test_dataset)  # Model predictions\n","\n","# Get predicted class labels (0 or 1)\n","y_pred_classes = np.argmax(y_pred, axis=1) \n","\n","# confusion matrix\n","cm = confusion_matrix(y_true, y_pred_classes)\n","\n","# Plotting the confusion matrix\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":501529,"sourceId":939937,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
